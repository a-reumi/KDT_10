{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "990563c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모듈 로딩\n",
    "## - 데이터 분석 및 시각화\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm   # 진행상황 시각화 (프로그레스바 progressbar)\n",
    "\n",
    "## 한국어_자연어_처리 형태소 분석기\n",
    "from konlpy.tag import Okt         \n",
    "\n",
    "## - Pytorch 관련\n",
    "import torch\n",
    "\n",
    "## - 데이터셋 : 학습용/검증용/테스트용 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## - Vocab 생성 시 단어 빈도 처리 위한 python 기본 모듈\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0bc082d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 준비\n",
    "DATA_FILE_TRAIN = '../data/open/train_data.csv'                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
    "DATA_FILE_TEST = '../data/open/test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "86322253",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(DATA_FILE_TRAIN)\n",
    "test_df=pd.read_csv(DATA_FILE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ae2d57f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45654 entries, 0 to 45653\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   index      45654 non-null  int64 \n",
      " 1   title      45654 non-null  object\n",
      " 2   topic_idx  45654 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fa81d505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9131 entries, 0 to 9130\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   index   9131 non-null   int64 \n",
      " 1   title   9131 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 142.8+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "971186f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측값 여부 : False\n"
     ]
    }
   ],
   "source": [
    "print('결측값 여부 :',train_df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1003453c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 개수\n",
      "                                   title  count\n",
      "0        070 스팸전화 인식 탓 인터넷전화 가입자 24만명 감소      1\n",
      "1              1.4㎏ 신경 덩어리 뇌의 신비 언제쯤 풀릴까      1\n",
      "2            1004·4989 인기번호 알뜰폰 가입자도 받아요      1\n",
      "3           1004·7942 이동전화 선호번호 범위 대폭 확대      1\n",
      "4       100년 넘은 미주 최후 멕시코 태평양 섬 교도소 문닫는다      1\n",
      "...                                  ...    ...\n",
      "45649  女배구대표팀 세계 1위 세르비아와 VNL 2차전서 13...      1\n",
      "45650      女아나운서 채용 차별 대전MBC 인권위 권고 이행하라      1\n",
      "45651   女축구 윤덕여 감독 끝이 아닌 시작…프랑스월드컵 선전하겠다      1\n",
      "45652  女프로배구 4개팀 시범경기 일정 확정…용병 거포 디우프 출격      1\n",
      "45653    女프로배구 기업은행 새 감독에 김우재 강릉여고 감독 내정      1\n",
      "\n",
      "[45654 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print('레이블 개수')\n",
    "print(train_df.groupby('title').size().reset_index(name='count')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f6c73fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = train_df['title'].tolist()\n",
    "y_data = train_df['topic_idx'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf0ae72",
   "metadata": {},
   "source": [
    "### 데이터셋 분리 : 학습용/검증용/테스트용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "092b490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터셋 분리 : 학습용/검증용/테스트용\n",
    "# 4. train / valid+test 먼저 나누기 (30%)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_data, y_data, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "70e8c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. valid / test 나누기 (15%씩)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, \n",
    "                                                test_size=0.5, \n",
    "                                                random_state=42, \n",
    "                                                stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "25d13a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 크기 : 31957\n",
      "검증 데이터 크기 : 6848\n",
      "테스트 데이터 크기 : 6849\n"
     ]
    }
   ],
   "source": [
    "# 확인\n",
    "print(f'학습 데이터 크기 : {len(X_train)}')\n",
    "print(f'검증 데이터 크기 : {len(X_val)}')\n",
    "print(f'테스트 데이터 크기 : {len(X_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e93f42c",
   "metadata": {},
   "source": [
    "### 단어사전 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4c761e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "okt_morphs = [okt.morphs(sent) for sent in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b7a5a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 함수 정의\n",
    "def tokenize(sentences):\n",
    "    tokenized_sentences = []\n",
    "    for sent in tqdm(sentences, desc=\"Tokenizing\"):\n",
    "        tokens = okt.morphs(sent)\n",
    "        tokens = [word.lower() for word in tokens]\n",
    "        # 불용어 제거, 원형복원, 구두점 추가해서 정리 \n",
    "        tokenized_sentences.append(tokens)\n",
    "    return tokenized_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "272558c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing: 100%|██████████| 31957/31957 [01:31<00:00, 351.02it/s] \n",
      "Tokenizing: 100%|██████████| 6848/6848 [00:07<00:00, 974.54it/s] \n",
      "Tokenizing: 100%|██████████| 6849/6849 [00:06<00:00, 986.63it/s] \n"
     ]
    }
   ],
   "source": [
    "# 실제 토큰화 수행\n",
    "tokenized_X_train = tokenize(X_train)\n",
    "tokenized_X_val = tokenize(X_val)\n",
    "tokenized_X_test = tokenize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "656bb412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['바르사', '알라베스', '국왕컵', '결승', '레알', '마드리드', '안방', '에선', '안', '돼']\n",
      "['lgu', '경기도', '시흥', '서', '5', 'g', '드론', '시연', '…', 'ai', '음성', '명령', '으로', '제어']\n"
     ]
    }
   ],
   "source": [
    "# 상위 샘플 2개 출력\n",
    "for sent in tokenized_X_train[:2]:\n",
    "  print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1603b831",
   "metadata": {},
   "source": [
    "### Vocab 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3f7218a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 단어수 : 30817\n"
     ]
    }
   ],
   "source": [
    "## 단어 추출 후 단어 빈도 처리 \n",
    "word_list = []\n",
    "for sent in tokenized_X_train:\n",
    "    for word in sent:\n",
    "      word_list.append(word)\n",
    "\n",
    "word_counts = Counter(word_list)\n",
    "print('총 단어수 :', len(word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "374fc4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "등장 빈도수 상위 10개 단어\n",
      "['…', '에', '·', '종합', '서', '의', '로', '한', '2', '명']\n",
      "등장 빈도수 하위 10개 단어\n",
      "['조급함', '입체파', '혁명가', '미운', '우동기', '버르장머리', '고치겠다', '전조', '쐈지만', '시큰둥']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "print('등장 빈도수 상위 10개 단어')\n",
    "print(vocab[:10])\n",
    "\n",
    "print('등장 빈도수 하위 10개 단어')\n",
    "print(vocab[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "95a55806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 30817\n",
      "등장 빈도가 2번 이하인 희귀 단어의 수: 18080\n",
      "단어 집합에서 희귀 단어의 비율: 58.668916507122695\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 6.481169613344827\n"
     ]
    }
   ],
   "source": [
    "threshold  = 3\n",
    "total_cnt  = len(word_counts) # 단어의 수\n",
    "rare_cnt   = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq  = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1b1af2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 12737\n"
     ]
    }
   ],
   "source": [
    "# 전체 단어 개수 중 빈도수 2이하인 단어는 제거.\n",
    "vocab_size = total_cnt - rare_cnt\n",
    "vocab = vocab[:vocab_size]\n",
    "print('단어 집합의 크기 :', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "56c4a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 단어사전 => 단어:정수값 \n",
    "word_to_index = {}\n",
    "word_to_index['<PAD>'] = 0\n",
    "word_to_index['<UNK>'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "61b46255",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, word in enumerate(vocab) :\n",
    "  word_to_index[word] = index + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "604928d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패딩 토큰과 UNK 토큰을 고려한 단어 집합의 크기 : 12739\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_index)\n",
    "print('패딩 토큰과 UNK 토큰을 고려한 단어 집합의 크기 :', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9f918f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 <PAD>와 맵핑되는 정수 : 0\n",
      "단어 <UNK>와 맵핑되는 정수 : 1\n"
     ]
    }
   ],
   "source": [
    "print('단어 <PAD>와 맵핑되는 정수 :', word_to_index['<PAD>'])\n",
    "print('단어 <UNK>와 맵핑되는 정수 :', word_to_index['<UNK>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c960ab02",
   "metadata": {},
   "source": [
    "### 정수 인코딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7412af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 문장 단위 추출 후 단어들을 정수로 인코딩 진행 함수 \n",
    "def texts_to_sequences(tokenized_X_data, word_to_index):\n",
    "  encoded_X_data = []\n",
    "  for sent in tokenized_X_data:\n",
    "    index_sequences = []\n",
    "    for word in sent:\n",
    "      # index_sequences.append(word_to_index.get(word, '<UNK>'))\n",
    "      try:\n",
    "          index_sequences.append(word_to_index[word])\n",
    "      except KeyError:\n",
    "          index_sequences.append(word_to_index['<UNK>'])\n",
    "    encoded_X_data.append(index_sequences)\n",
    "  return encoded_X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "85c3aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 토큰화 (변수명 통일: train / val / test)\n",
    "# tokenized_X_train = tokenize(X_train)\n",
    "# tokenized_X_val = tokenize(X_val)\n",
    "# tokenized_X_test = tokenize(X_test)\n",
    "\n",
    "# 2. 정수 인코딩\n",
    "encoded_X_train = texts_to_sequences(tokenized_X_train, word_to_index)\n",
    "encoded_X_val = texts_to_sequences(tokenized_X_val, word_to_index)\n",
    "encoded_X_test = texts_to_sequences(tokenized_X_test, word_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bedf8f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2102, 1, 7559, 879, 1690, 1825, 3842, 3257, 59, 319]\n",
      "[455, 1110, 1, 6, 26, 51, 706, 2460, 2, 141, 1640, 1776, 20, 3118]\n",
      "['바르사', '알라베스', '국왕컵', '결승', '레알', '마드리드', '안방', '에선', '안', '돼']\n",
      "['lgu', '경기도', '시흥', '서', '5', 'g', '드론', '시연', '…', 'ai', '음성', '명령', '으로', '제어']\n"
     ]
    }
   ],
   "source": [
    "# 상위 샘플 2개 출력\n",
    "for sent in encoded_X_train[:2]:\n",
    "  print(sent)\n",
    "\n",
    "for sent in tokenized_X_train[:2]:\n",
    "  print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f241a124",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 정수 => 단어 변환 사전 ( 예 : 영한사전, 기계어자연어사전 )\n",
    "index_to_word = {}\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a6c7ecc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존의 첫번째 샘플 : ['바르사', '알라베스', '국왕컵', '결승', '레알', '마드리드', '안방', '에선', '안', '돼']\n",
      "복원된 첫번째 샘플 : ['바르사', '<UNK>', '국왕컵', '결승', '레알', '마드리드', '안방', '에선', '안', '돼']\n"
     ]
    }
   ],
   "source": [
    "decoded_sample = [index_to_word[word] for word in encoded_X_train[0]]\n",
    "print('기존의 첫번째 샘플 :', tokenized_X_train[0])\n",
    "print('복원된 첫번째 샘플 :', decoded_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e289a3ba",
   "metadata": {},
   "source": [
    "### 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "30bb0617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 22\n",
      "리뷰의 평균 길이 : 10.962793754107082\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('리뷰의 최대 길이 :',max(len(review) for review in encoded_X_train))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, encoded_X_train))/len(encoded_X_train))\n",
    "plt.hist([len(review) for review in encoded_X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0cf41ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  count = 0\n",
    "  for sentence in nested_list:\n",
    "    if(len(sentence) <= max_len):\n",
    "        count = count + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7c7accd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 500 이하인 샘플의 비율: 100.0\n"
     ]
    }
   ],
   "source": [
    "max_len = 500\n",
    "below_threshold_len(max_len, encoded_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7aab9b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sentences, max_len):\n",
    "  features = np.zeros((len(sentences), max_len), dtype=int)\n",
    "  for index, sentence in enumerate(sentences):\n",
    "    if len(sentence) != 0:\n",
    "      features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b41d3bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782825d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "\n",
    "# 최대 길이 설정 (예시: 그래프에서 본 최대값 14)\n",
    "max_len = 14  # 또는 평균+표준편차 고려해서 설정\n",
    "\n",
    "# 패딩 적용 (변수명 일치시켜야 함!)\n",
    "padded_X_train = pad_sequences(encoded_X_train, maxlen=max_len, padding='post', truncating='post')\n",
    "padded_X_val   = pad_sequences(encoded_X_val, maxlen=max_len, padding='post', truncating='post')\n",
    "padded_X_test  = pad_sequences(encoded_X_test, maxlen=max_len, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cacd73be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 크기 : (31957, 14)\n",
      "검증 데이터의 크기 : (6848, 14)\n",
      "테스트 데이터의 크기 : (6849, 14)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 크기 :', padded_X_train.shape)\n",
    "print('검증 데이터의 크기 :', padded_X_val.shape) \n",
    "print('테스트 데이터의 크기 :', padded_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0740010b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31957, 14)\n"
     ]
    }
   ],
   "source": [
    "print(padded_X_train.shape[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d053bc87",
   "metadata": {},
   "source": [
    "### 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "55075c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b16050ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_tensor = torch.tensor(np.array(y_train))\n",
    "val_label_tensor   = torch.tensor(np.array(y_val))\n",
    "test_label_tensor  = torch.tensor(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "41228fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 4, 5], dtype=torch.int32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_tensor[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "44af78ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu와 cuda 중 다음 기기로 학습함: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"cpu와 cuda 중 다음 기기로 학습함:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a32a4cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1d 결과 shape: torch.Size([32, 33, 12])\n"
     ]
    }
   ],
   "source": [
    "# 1. 실제 입력 (예: padded_X_train은 (batch, seq_len) 모양의 정수 인코딩 텐서)\n",
    "input = torch.tensor(padded_X_train[:32], dtype=torch.long)  # (32, 50) → 배치 크기 32, 문장 길이 50\n",
    "\n",
    "# 2. 임베딩 적용\n",
    "embedding = nn.Embedding(num_embeddings=len(word_to_index), embedding_dim=16, padding_idx=0)\n",
    "embedded = embedding(input)  # (32, 50, 16)\n",
    "\n",
    "# 3. Conv1d를 위해 (배치, 채널, 시퀀스 길이)로 차원 변경\n",
    "embedded = embedded.permute(0, 2, 1)  # (32, 16, 50)\n",
    "\n",
    "# 4. Conv1d 선언 및 적용\n",
    "m = nn.Conv1d(in_channels=16, out_channels=33, kernel_size=3, stride=1)\n",
    "output = m(embedded)\n",
    "\n",
    "# 5. 출력 확인\n",
    "print(\"Conv1d 결과 shape:\", output.shape)  # (32, 33, 48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e7ecdec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "  def __init__(self, vocab_size, num_labels):\n",
    "    super(CNN, self).__init__()\n",
    "\n",
    "    # 오직 하나의 종류의 필터만 사용함.\n",
    "    self.num_filter_sizes = 1 # 윈도우 5짜리 1개만 사용\n",
    "    self.num_filters = 256\n",
    "\n",
    "    self.word_embed = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=128, padding_idx=0)\n",
    "    # 윈도우 5짜리 1개만 사용\n",
    "    self.conv1 = torch.nn.Conv1d(128, self.num_filters, 5, stride=1)\n",
    "    self.dropout = torch.nn.Dropout(0.5)\n",
    "    self.fc1 = torch.nn.Linear(1 * self.num_filters, num_labels, bias=True)\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    # word_embed(inputs).shape == (배치 크기, 문장길이, 임베딩 벡터의 차원)\n",
    "    # word_embed(inputs).permute(0, 2, 1).shape == (배치 크기, 임베딩 벡터의 차원, 문장 길이)\n",
    "    embedded = self.word_embed(inputs).permute(0, 2, 1)\n",
    "\n",
    "    # max를 이용한 maxpooling\n",
    "    # conv1(embedded).shape == (배치 크기, 커널 개수, 컨볼루션 연산 결과) == ex) 32, 256, 496\n",
    "    # conv1(embedded).permute(0, 2, 1).shape == (배치 크기, 컨볼루션 연산 결과, 커널 개수)\n",
    "    # conv1(embedded).permute(0, 2, 1).max(1)[0]).shape == (배치 크기, 커널 개수)\n",
    "    x = F.relu(self.conv1(embedded).permute(0, 2, 1).max(1)[0])\n",
    "\n",
    "    # y_pred.shape == (배치 크기, 분류할 카테고리의 수)\n",
    "    y_pred = self.fc1(self.dropout(x))\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2d3ff50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 변수 이름 통일\n",
    "padded_X_valid = padded_X_val\n",
    "valid_label_tensor = torch.tensor(y_val)\n",
    "\n",
    "# Tensor 변환 및 Dataset 구성\n",
    "encoded_train = torch.tensor(padded_X_train).to(torch.int64)\n",
    "train_label_tensor = torch.tensor(y_train)\n",
    "train_dataset = torch.utils.data.TensorDataset(encoded_train, train_label_tensor)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "\n",
    "encoded_test = torch.tensor(padded_X_test).to(torch.int64)\n",
    "test_label_tensor = torch.tensor(y_test)\n",
    "test_dataset = torch.utils.data.TensorDataset(encoded_test, test_label_tensor)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=True, batch_size=1)\n",
    "\n",
    "encoded_valid = torch.tensor(padded_X_valid).to(torch.int64)\n",
    "valid_dataset = torch.utils.data.TensorDataset(encoded_valid, valid_label_tensor)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, shuffle=True, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d2f86c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 배치의 수 : 999\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "total_batch = len(train_dataloader)\n",
    "print('총 배치의 수 : {}'.format(total_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7fb06965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (word_embed): Embedding(12739, 128, padding_idx=0)\n",
       "  (conv1): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=256, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN(vocab_size, num_labels = len(set(y_train)))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ccb54b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "502c96ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(logits, labels):\n",
    "    # _, predicted = torch.max(logits, 1)\n",
    "    predicted = torch.argmax(logits, dim=1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "970495b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, valid_dataloader, criterion, device):\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 데이터로더로부터 배치 크기만큼의 데이터를 연속으로 로드\n",
    "        for batch_X, batch_y in valid_dataloader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            # 모델의 예측값\n",
    "            logits = model(batch_X)\n",
    "\n",
    "            # 손실을 계산\n",
    "            loss = criterion(logits, batch_y)\n",
    "\n",
    "            # 정확도와 손실을 계산함\n",
    "            val_loss += loss.item()\n",
    "            val_correct += calculate_accuracy(logits, batch_y) * batch_y.size(0)\n",
    "            val_total += batch_y.size(0)\n",
    "\n",
    "    val_accuracy = val_correct / val_total\n",
    "    val_loss /= len(valid_dataloader)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "25f8cadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:\n",
      "Train Loss: 1.3454, Train Accuracy: 0.5052\n",
      "Validation Loss: 0.8904, Validation Accuracy: 0.6993\n",
      "Validation loss improved from inf to 0.8904. 체크포인트를 저장합니다.\n",
      "Epoch 2/5:\n",
      "Train Loss: 0.7783, Train Accuracy: 0.7316\n",
      "Validation Loss: 0.7362, Validation Accuracy: 0.7512\n",
      "Validation loss improved from 0.8904 to 0.7362. 체크포인트를 저장합니다.\n",
      "Epoch 3/5:\n",
      "Train Loss: 0.5580, Train Accuracy: 0.8110\n",
      "Validation Loss: 0.6716, Validation Accuracy: 0.7858\n",
      "Validation loss improved from 0.7362 to 0.6716. 체크포인트를 저장합니다.\n",
      "Epoch 4/5:\n",
      "Train Loss: 0.4246, Train Accuracy: 0.8538\n",
      "Validation Loss: 0.6619, Validation Accuracy: 0.7899\n",
      "Validation loss improved from 0.6716 to 0.6619. 체크포인트를 저장합니다.\n",
      "Epoch 5/5:\n",
      "Train Loss: 0.3247, Train Accuracy: 0.8889\n",
      "Validation Loss: 0.6881, Validation Accuracy: 0.8008\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    model.train()\n",
    "    for batch_X, batch_y in train_dataloader:\n",
    "        # Forward pass\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        # batch_X.shape == (batch_size, max_len)\n",
    "        logits = model(batch_X)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(logits, batch_y)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate training accuracy and loss\n",
    "        train_loss += loss.item()\n",
    "        train_correct += calculate_accuracy(logits, batch_y) * batch_y.size(0)\n",
    "        train_total += batch_y.size(0)\n",
    "\n",
    "    train_accuracy = train_correct / train_total\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    # Validation\n",
    "    val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # 검증 손실이 최소일 때 체크포인트 저장\n",
    "    if val_loss < best_val_loss:\n",
    "        print(f'Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. 체크포인트를 저장합니다.')\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d25c8732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model validation loss: 0.6619\n",
      "Best model validation accuracy: 0.7899\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드\n",
    "model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n",
    "\n",
    "# 모델을 device에 올립니다.\n",
    "model.to(device)\n",
    "\n",
    "# 검증 데이터에 대한 정확도와 손실 계산\n",
    "val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n",
    "\n",
    "print(f'Best model validation loss: {val_loss:.4f}')\n",
    "print(f'Best model validation accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3c89f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model, word_to_index, index_to_tag):\n",
    "    # 모델 평가 모드\n",
    "    model.eval()\n",
    "\n",
    "    # 토큰화 및 정수 인코딩. OOV 문제 발생 시 <UNK> 토큰에 해당하는 인덱스 1 할당\n",
    "    tokens = okt.morphs(text)  \n",
    "    token_indices = [word_to_index.get(token.lower(), 1) for token in tokens]\n",
    "\n",
    "    # 리스트를 텐서로 변경\n",
    "    input_tensor = torch.tensor([token_indices], dtype=torch.long).to(device)  # (1, seq_length)\n",
    "\n",
    "    # 모델의 예측\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)  # (1, output_dim)\n",
    "\n",
    "    # 레이블 인덱스 예측\n",
    "    _, predicted_index = torch.max(logits, dim=1)  # (1,)\n",
    "\n",
    "    # 인덱스와 매칭되는 카테고리 문자열로 변경\n",
    "    predicted_tag = index_to_tag[predicted_index.item()]\n",
    "\n",
    "    return predicted_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "452b9057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 집합 크기\n",
    "vocab_size = len(word_to_index)  # 꼭 word_to_index 기반으로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4d11a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 단방향 모델 정의\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim, output_dim):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=128, padding_idx=0)\n",
    "        self.rnn = nn.RNN(input_size=128, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  # (batch, seq_len, embed_dim)\n",
    "        output, hidden = self.rnn(embedded)  # hidden: (1, batch, hidden_dim)\n",
    "        return self.fc(hidden.squeeze(0))  # (batch, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0b224728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(12739, 128, padding_idx=0)\n",
       "  (rnn): RNN(128, 128, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = RNN(vocab_size=vocab_size, hidden_dim=128, output_dim=len(set(y_train)))\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6248eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수와 옵티마이저 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2e482298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 계산 함수\n",
    "def calculate_accuracy(logits, labels):\n",
    "    predicted = torch.argmax(logits, dim=1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9349b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증용 평가 함수\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, total_correct, total = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            logits = model(batch_X)\n",
    "            loss = criterion(logits, batch_y)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += calculate_accuracy(logits, batch_y) * batch_y.size(0)\n",
    "            total += batch_y.size(0)\n",
    "\n",
    "    return total_loss / len(dataloader), total_correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6c07bed0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[166], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 17\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     20\u001b[0m train_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m calculate_accuracy(logits, batch_y) \u001b[38;5;241m*\u001b[39m batch_y\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kdp\\anaconda3\\envs\\NLP\\lib\\site-packages\\torch\\optim\\optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m             )\n\u001b[1;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kdp\\anaconda3\\envs\\NLP\\lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\kdp\\anaconda3\\envs\\NLP\\lib\\site-packages\\torch\\optim\\adam.py:168\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    160\u001b[0m         group,\n\u001b[0;32m    161\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    166\u001b[0m         state_steps)\n\u001b[1;32m--> 168\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\kdp\\anaconda3\\envs\\NLP\\lib\\site-packages\\torch\\optim\\adam.py:318\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 318\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kdp\\anaconda3\\envs\\NLP\\lib\\site-packages\\torch\\optim\\adam.py:393\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    390\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(param)\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    394\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "num_epochs = 20\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_correct, train_total = 0, 0, 0\n",
    "    model.train()\n",
    "\n",
    "    for batch_X, batch_y in train_dataloader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        logits = model(batch_X)\n",
    "        loss = criterion(logits, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_correct += calculate_accuracy(logits, batch_y) * batch_y.size(0)\n",
    "        train_total += batch_y.size(0)\n",
    "\n",
    "    train_accuracy = train_correct / train_total\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_rnn_model.pth')\n",
    "        print(\"Best model saved.\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "62645b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 에폭 1/20\n",
      "훈련 손실: 0.1296, 훈련 정확도: 0.9666\n",
      "검증 손실: 0.9586, 검증 정확도: 0.7830\n",
      "✅ 성능 향상: 모델 저장 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 에폭 2/20\n",
      "훈련 손실: 0.1225, 훈련 정확도: 0.9680\n",
      "검증 손실: 0.9915, 검증 정확도: 0.7750\n",
      "⚠️ 성능 향상 없음. (1/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 에폭 3/20\n",
      "훈련 손실: 0.1118, 훈련 정확도: 0.9718\n",
      "검증 손실: 1.0502, 검증 정확도: 0.7815\n",
      "⚠️ 성능 향상 없음. (2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📘 에폭 4/20\n",
      "훈련 손실: 0.1009, 훈련 정확도: 0.9729\n",
      "검증 손실: 1.0317, 검증 정확도: 0.7839\n",
      "⚠️ 성능 향상 없음. (3/3)\n",
      "🛑 조기 종료: 검증 손실이 개선되지 않았습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = 20\n",
    "best_val_loss = float('inf')\n",
    "patience = 3               # 몇 번 연속 성능 향상 없을 때 멈출지\n",
    "no_improve_epochs = 0      # 성능 향상 안 된 에폭 수\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_correct, train_total = 0, 0, 0\n",
    "    model.train()\n",
    "\n",
    "    # ✅ tqdm 진행률 표시\n",
    "    train_bar = tqdm(train_dataloader, desc=f\"[에폭 {epoch+1}/{num_epochs}] 학습 중\", leave=False)\n",
    "\n",
    "    for batch_X, batch_y in train_bar:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        logits = model(batch_X)\n",
    "        loss = criterion(logits, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_correct += calculate_accuracy(logits, batch_y) * batch_y.size(0)\n",
    "        train_total += batch_y.size(0)\n",
    "\n",
    "        train_bar.set_postfix({\n",
    "            \"손실\": f\"{loss.item():.4f}\"\n",
    "        })\n",
    "\n",
    "    train_accuracy = train_correct / train_total\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n",
    "\n",
    "    print(f\"\\n📘 에폭 {epoch+1}/{num_epochs}\")\n",
    "    print(f\"훈련 손실: {train_loss:.4f}, 훈련 정확도: {train_accuracy:.4f}\")\n",
    "    print(f\"검증 손실: {val_loss:.4f}, 검증 정확도: {val_accuracy:.4f}\")\n",
    "\n",
    "    # ✅ 조기 종료 조건 확인\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improve_epochs = 0\n",
    "        torch.save(model.state_dict(), 'best_model1.pth')\n",
    "        print(\"✅ 성능 향상: 모델 저장 완료.\")\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "        print(f\"⚠️ 성능 향상 없음. ({no_improve_epochs}/{patience})\")\n",
    "\n",
    "        if no_improve_epochs >= patience:\n",
    "            print(\"🛑 조기 종료: 검증 손실이 개선되지 않았습니다.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c33e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 20\n",
    "# best_val_loss = float('inf')\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_loss, train_correct, train_total = 0, 0, 0\n",
    "#     model.train()\n",
    "\n",
    "#     # tqdm으로 배치 단위 진행률 출력\n",
    "#     progress_bar = tqdm(train_dataloader, desc=f\"[에폭 {epoch+1}/{num_epochs}] 학습 중\", leave=False)\n",
    "\n",
    "#     for step, (batch_X, batch_y) in enumerate(progress_bar):\n",
    "#         batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "#         logits = model(batch_X)\n",
    "#         loss = criterion(logits, batch_y)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         train_loss += loss.item()\n",
    "#         train_correct += calculate_accuracy(logits, batch_y) * batch_y.size(0)\n",
    "#         train_total += batch_y.size(0)\n",
    "\n",
    "#         # 현재 진행률 퍼센트로 업데이트\n",
    "#         percent = 100 * (step + 1) / len(train_dataloader)\n",
    "#         progress_bar.set_postfix({\n",
    "#             \"진행률\": f\"{percent:.1f}%\",\n",
    "#             \"현재 손실\": f\"{loss.item():.4f}\"\n",
    "#         })\n",
    "\n",
    "#     train_accuracy = train_correct / train_total\n",
    "#     train_loss /= len(train_dataloader)\n",
    "\n",
    "#     val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n",
    "\n",
    "#     print(f'\\n에폭 {epoch+1}/{num_epochs}')\n",
    "#     print(f'훈련 손실: {train_loss:.4f}, 훈련 정확도: {train_accuracy:.4f}')\n",
    "#     print(f'검증 손실: {val_loss:.4f}, 검증 정확도: {val_accuracy:.4f}')\n",
    "\n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         torch.save(model.state_dict(), 'best_rnn_model.pth')\n",
    "#         print(\" 검증 성능 향상 → 모델 저장됨.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a0377c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7906\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드 및 테스트 평가\n",
    "model.load_state_dict(torch.load('best_rnn_model.pth'))\n",
    "model.to(device)\n",
    "test_loss, test_acc = evaluate(model, test_dataloader, criterion, device)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f9ca7dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(vocab_size, num_labels = len(set(y_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b73894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657b3bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7f80c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa6b821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a00c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea88d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7d24e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d2345",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEWS = '../data/open/topic_dict.csv'\n",
    "news_df = pd.read_csv(NEWS)\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ffd77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da753dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fdfead",
   "metadata": {},
   "source": [
    "데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30276743",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모듈로딩\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91155302",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.iloc[:50,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06675c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 문자 집합 생성\n",
    "chars = sorted(list(set(train_df.iloc[:50,1])))\n",
    "print(f'chars => {chars}')\n",
    "\n",
    "vocab_size = len(chars)\n",
    "print(f'vocab_size => ', vocab_size)\n",
    "\n",
    "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx_to_char = {i: ch for i, ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e979356",
   "metadata": {},
   "source": [
    "- 토큰화 -> 형태소 분석기 선택\n",
    "- 단어 사전"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333142f5",
   "metadata": {},
   "source": [
    "형태소 분석\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bc9e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 형태소 분석기 인스턴스 객체 생성\n",
    "okt_tokenizer= Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c442fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_datas=train_df.iloc[:50,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d49baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 추가\n",
    "\n",
    "stopword_file = './koreanStopwords_unique.txt'\n",
    "\n",
    "with open(stopword_file, mode='r', encoding='utf-8') as f:\n",
    "    stop_words = f.readlines()\n",
    "\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8007bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datas=train_df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a1f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 마다 토큰 분리\n",
    "token_datas=[]\n",
    "for sentence in all_datas:\n",
    "    wtoken=okt_tokenizer.morphs(sentence)  # 명사만 morphs 말고 nouns\n",
    "    # 불용어만 제거 (품사 제거 등 다른 작업도 해야 함)\n",
    "    ww=[w for w in wtoken if w not in stop_words]\n",
    "    token_datas.append(ww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76720c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 마다 토큰 분리\n",
    "token_datas2=[]\n",
    "for sentence in all_datas:\n",
    "    wtoken=okt_tokenizer.nouns(sentence)  # 명사만 morphs 말고 nouns\n",
    "    # 불용어만 제거 (품사 제거 등 다른 작업도 해야 함)\n",
    "    ww=[w for w in wtoken if w not in stop_words]\n",
    "    token_datas2.append(ww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8145cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('문장별 토큰화 결과 : ', len(token_datas))\n",
    "token_datas[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfe9b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8fc1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('문장별 토큰화 결과 : ', len(token_datas2))\n",
    "token_datas2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f843d711",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList=[]\n",
    "for tt in token_datas:\n",
    "    print(tt)\n",
    "    wordList += tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcfc873",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wordList), wordList[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23609f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 중복된 단어 제거\n",
    "key_list= set(wordList)\n",
    "len(key_list), key_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df63392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 단어/토큰별 빈도 수 정장을 위한 dict => 0으로 초기화\n",
    "voca={ key: 0 for key in key_list}\n",
    "voca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf7c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 단어/토큰별 빈도 수 저장\n",
    "for word in wordList:\n",
    "    voca[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefae259",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터프레임에 저장\n",
    "vocaDF=pd.DataFrame([voca]).T\n",
    "vocaDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c7cf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60258eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocaDF.to_excel('voca_check.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0b189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## - 빈도순으로 정렬\n",
    "vocaDF2=vocaDF.sort_values(0, ascending=False)\n",
    "vocaDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c6902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afc317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocaDF2[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4204e1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739864c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 토큰관련 특별 문자\n",
    "UNK = '<UNK>'\n",
    "PAD = '<PAD>'\n",
    "\n",
    "### 토큰화 인스턴스 생성\n",
    "tokenizer = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f0e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 토큰 제너레이터 함수 : 데이터 추출하여 토큰화 \n",
    "def yield_tokens(data_iter):\n",
    "    for label, text in data_iter:\n",
    "        # 라벨, 텍스트 --> 텍스트 토큰화\n",
    "        yield tokenizer.morphs(text, stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0c0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 토큰화 및 단어/어휘 사전 생성\n",
    "VOCAB = build_vocab_from_iterator(\n",
    "    yield_tokens(train_df),\n",
    "    min_freq=2,\n",
    "    specials= [PAD, UNK],\n",
    "    special_first=True\n",
    ")\n",
    "\n",
    "### <UNK> 인덱스 설정\n",
    "VOCAB.set_default_index(VOCAB[UNK])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfa9f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e1185a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a39d91e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09656a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
